{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Activation, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "import keras.optimizers as optimizers\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend import tensorflow_backend\n",
    "\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "session = tf.Session(config=config)\n",
    "tensorflow_backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 200, 200\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 200\n",
    "STEPS = 10\n",
    "CATEGORY = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_names = [name for name in os.listdir(train_data_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disgust',\n",
       " 'happiness',\n",
       " 'sadness',\n",
       " 'surprised',\n",
       " 'neutral',\n",
       " 'angry',\n",
       " 'contempt',\n",
       " 'fear']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルを作る\n",
    "def inceptionV3fc_model():\n",
    "    input_tensor = Input(shape=(img_height, img_width, 3))\n",
    "    inceptionv3 = InceptionV3(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "    \n",
    "    # 全結合１\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=inceptionv3.output_shape[1:]))\n",
    "    top_model.add(Dense(512, name=\"dense1\"))\n",
    "    top_model.add(Activation(\"relu\"))\n",
    "    top_model.add(Dropout(0.5))\n",
    "        \n",
    "    # 出力\n",
    "    top_model.add(Dense(8, name='output'))\n",
    "    top_model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    # 接続\n",
    "    model = Model(inputs=inceptionv3.input, outputs=top_model(inceptionv3.output))\n",
    "    \n",
    "    # 元の特徴抽出部分は更新しない\n",
    "#    for layer in model.layers[:249]:\n",
    "#        layer.trainable = False\n",
    "#    for layer in model.layers[249:]:\n",
    "#        layer.trainable = True\n",
    "\n",
    "    for layer in model.layers[:241]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[241:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "        \n",
    "#    for i, layer in enumerate(model.layers):\n",
    "#        print(str(i) + \": \" + layer.name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = inceptionV3fc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 200, 200, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 99, 99, 32)    864         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 99, 99, 32)    96          conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 99, 99, 32)    0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 97, 97, 32)    9216        activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 97, 97, 32)    96          conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 97, 97, 32)    0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 97, 97, 64)    18432       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 97, 97, 64)    192         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 97, 97, 64)    0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 48, 48, 64)    0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 48, 48, 80)    5120        max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 48, 48, 80)    240         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 48, 48, 80)    0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 46, 46, 192)   138240      activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 46, 46, 192)   576         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 46, 46, 192)   0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 22, 22, 192)   0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 22, 22, 64)    12288       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 22, 22, 64)    192         conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 22, 22, 64)    0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 22, 22, 48)    9216        max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 22, 22, 96)    55296       activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 22, 22, 48)    144         conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 22, 22, 96)    288         conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 22, 22, 48)    0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 22, 22, 96)    0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePool (None, 22, 22, 192)   0           max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 22, 22, 64)    12288       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 22, 22, 64)    76800       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 22, 22, 96)    82944       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 22, 22, 32)    6144        average_pooling2d_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 22, 22, 64)    192         conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 22, 22, 64)    192         conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 22, 22, 96)    288         conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 22, 22, 32)    96          conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 22, 22, 64)    0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 22, 22, 64)    0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 22, 22, 96)    0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 22, 22, 32)    0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)             (None, 22, 22, 256)   0           activation_6[0][0]               \n",
      "                                                                   activation_8[0][0]               \n",
      "                                                                   activation_11[0][0]              \n",
      "                                                                   activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 22, 22, 64)    16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, 22, 22, 64)    192         conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 22, 22, 64)    0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 22, 22, 48)    12288       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 22, 22, 96)    55296       activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 22, 22, 48)    144         conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, 22, 22, 96)    288         conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 22, 22, 48)    0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 22, 22, 96)    0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePool (None, 22, 22, 256)   0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 22, 22, 64)    16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 22, 22, 64)    76800       activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 22, 22, 96)    82944       activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 22, 22, 64)    16384       average_pooling2d_2[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 22, 22, 64)    192         conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, 22, 22, 64)    192         conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, 22, 22, 96)    288         conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, 22, 22, 64)    192         conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 22, 22, 64)    0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 22, 22, 64)    0           batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 22, 22, 96)    0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 22, 22, 64)    0           batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)             (None, 22, 22, 288)   0           activation_13[0][0]              \n",
      "                                                                   activation_15[0][0]              \n",
      "                                                                   activation_18[0][0]              \n",
      "                                                                   activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 22, 22, 64)    18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, 22, 22, 64)    192         conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 22, 22, 64)    0           batch_normalization_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 22, 22, 48)    13824       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 22, 22, 96)    55296       activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, 22, 22, 48)    144         conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, 22, 22, 96)    288         conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 22, 22, 48)    0           batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 22, 22, 96)    0           batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePool (None, 22, 22, 288)   0           mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 22, 22, 64)    18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 22, 22, 64)    76800       activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 22, 22, 96)    82944       activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 22, 22, 64)    18432       average_pooling2d_3[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, 22, 22, 64)    192         conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, 22, 22, 64)    192         conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, 22, 22, 96)    288         conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, 22, 22, 64)    192         conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 22, 22, 64)    0           batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 22, 22, 64)    0           batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 22, 22, 96)    0           batch_normalization_25[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 22, 22, 64)    0           batch_normalization_26[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)             (None, 22, 22, 288)   0           activation_20[0][0]              \n",
      "                                                                   activation_22[0][0]              \n",
      "                                                                   activation_25[0][0]              \n",
      "                                                                   activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 22, 22, 64)    18432       mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, 22, 22, 64)    192         conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 22, 22, 64)    0           batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 22, 22, 96)    55296       activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, 22, 22, 96)    288         conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 22, 22, 96)    0           batch_normalization_29[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 10, 10, 384)   995328      mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 10, 10, 96)    82944       activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, 10, 10, 384)   1152        conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, 10, 10, 96)    288         conv2d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 10, 10, 384)   0           batch_normalization_27[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 10, 10, 96)    0           batch_normalization_30[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 10, 10, 288)   0           mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)             (None, 10, 10, 768)   0           activation_27[0][0]              \n",
      "                                                                   activation_30[0][0]              \n",
      "                                                                   max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, 10, 10, 128)   98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNor (None, 10, 10, 128)   384         conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 10, 10, 128)   0           batch_normalization_35[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, 10, 10, 128)   114688      activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNor (None, 10, 10, 128)   384         conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 10, 10, 128)   0           batch_normalization_36[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, 10, 10, 128)   98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, 10, 10, 128)   114688      activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, 10, 10, 128)   384         conv2d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNor (None, 10, 10, 128)   384         conv2d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 10, 10, 128)   0           batch_normalization_32[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 10, 10, 128)   0           batch_normalization_37[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, 10, 10, 128)   114688      activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, 10, 10, 128)   114688      activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, 10, 10, 128)   384         conv2d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNor (None, 10, 10, 128)   384         conv2d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 10, 10, 128)   0           batch_normalization_33[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 10, 10, 128)   0           batch_normalization_38[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePool (None, 10, 10, 768)   0           mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, 10, 10, 192)   147456      mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, 10, 10, 192)   172032      activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)               (None, 10, 10, 192)   172032      activation_38[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, 10, 10, 192)   147456      average_pooling2d_4[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, 10, 10, 192)   576         conv2d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, 10, 10, 192)   576         conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNor (None, 10, 10, 192)   576         conv2d_39[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNor (None, 10, 10, 192)   576         conv2d_40[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 10, 10, 192)   0           batch_normalization_31[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 10, 10, 192)   0           batch_normalization_34[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, 10, 10, 192)   0           batch_normalization_39[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, 10, 10, 192)   0           batch_normalization_40[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)             (None, 10, 10, 768)   0           activation_31[0][0]              \n",
      "                                                                   activation_34[0][0]              \n",
      "                                                                   activation_39[0][0]              \n",
      "                                                                   activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)               (None, 10, 10, 160)   122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNor (None, 10, 10, 160)   480         conv2d_45[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, 10, 10, 160)   0           batch_normalization_45[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)               (None, 10, 10, 160)   179200      activation_45[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNor (None, 10, 10, 160)   480         conv2d_46[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_46 (Activation)       (None, 10, 10, 160)   0           batch_normalization_46[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)               (None, 10, 10, 160)   122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)               (None, 10, 10, 160)   179200      activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNor (None, 10, 10, 160)   480         conv2d_42[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNor (None, 10, 10, 160)   480         conv2d_47[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_42 (Activation)       (None, 10, 10, 160)   0           batch_normalization_42[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_47 (Activation)       (None, 10, 10, 160)   0           batch_normalization_47[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)               (None, 10, 10, 160)   179200      activation_42[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)               (None, 10, 10, 160)   179200      activation_47[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNor (None, 10, 10, 160)   480         conv2d_43[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNor (None, 10, 10, 160)   480         conv2d_48[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, 10, 10, 160)   0           batch_normalization_43[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_48 (Activation)       (None, 10, 10, 160)   0           batch_normalization_48[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePool (None, 10, 10, 768)   0           mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)               (None, 10, 10, 192)   147456      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)               (None, 10, 10, 192)   215040      activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)               (None, 10, 10, 192)   215040      activation_48[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)               (None, 10, 10, 192)   147456      average_pooling2d_5[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNor (None, 10, 10, 192)   576         conv2d_41[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNor (None, 10, 10, 192)   576         conv2d_44[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNor (None, 10, 10, 192)   576         conv2d_49[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNor (None, 10, 10, 192)   576         conv2d_50[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_41 (Activation)       (None, 10, 10, 192)   0           batch_normalization_41[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, 10, 10, 192)   0           batch_normalization_44[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_49 (Activation)       (None, 10, 10, 192)   0           batch_normalization_49[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_50 (Activation)       (None, 10, 10, 192)   0           batch_normalization_50[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)             (None, 10, 10, 768)   0           activation_41[0][0]              \n",
      "                                                                   activation_44[0][0]              \n",
      "                                                                   activation_49[0][0]              \n",
      "                                                                   activation_50[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)               (None, 10, 10, 160)   122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNor (None, 10, 10, 160)   480         conv2d_55[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_55 (Activation)       (None, 10, 10, 160)   0           batch_normalization_55[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)               (None, 10, 10, 160)   179200      activation_55[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNor (None, 10, 10, 160)   480         conv2d_56[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_56 (Activation)       (None, 10, 10, 160)   0           batch_normalization_56[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)               (None, 10, 10, 160)   122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)               (None, 10, 10, 160)   179200      activation_56[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNor (None, 10, 10, 160)   480         conv2d_52[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNor (None, 10, 10, 160)   480         conv2d_57[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_52 (Activation)       (None, 10, 10, 160)   0           batch_normalization_52[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_57 (Activation)       (None, 10, 10, 160)   0           batch_normalization_57[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)               (None, 10, 10, 160)   179200      activation_52[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)               (None, 10, 10, 160)   179200      activation_57[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNor (None, 10, 10, 160)   480         conv2d_53[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNor (None, 10, 10, 160)   480         conv2d_58[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_53 (Activation)       (None, 10, 10, 160)   0           batch_normalization_53[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_58 (Activation)       (None, 10, 10, 160)   0           batch_normalization_58[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePool (None, 10, 10, 768)   0           mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)               (None, 10, 10, 192)   147456      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)               (None, 10, 10, 192)   215040      activation_53[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)               (None, 10, 10, 192)   215040      activation_58[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)               (None, 10, 10, 192)   147456      average_pooling2d_6[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNor (None, 10, 10, 192)   576         conv2d_51[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNor (None, 10, 10, 192)   576         conv2d_54[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNor (None, 10, 10, 192)   576         conv2d_59[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNor (None, 10, 10, 192)   576         conv2d_60[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_51 (Activation)       (None, 10, 10, 192)   0           batch_normalization_51[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_54 (Activation)       (None, 10, 10, 192)   0           batch_normalization_54[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_59 (Activation)       (None, 10, 10, 192)   0           batch_normalization_59[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_60 (Activation)       (None, 10, 10, 192)   0           batch_normalization_60[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)             (None, 10, 10, 768)   0           activation_51[0][0]              \n",
      "                                                                   activation_54[0][0]              \n",
      "                                                                   activation_59[0][0]              \n",
      "                                                                   activation_60[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)               (None, 10, 10, 192)   147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNor (None, 10, 10, 192)   576         conv2d_65[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_65 (Activation)       (None, 10, 10, 192)   0           batch_normalization_65[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)               (None, 10, 10, 192)   258048      activation_65[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNor (None, 10, 10, 192)   576         conv2d_66[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_66 (Activation)       (None, 10, 10, 192)   0           batch_normalization_66[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)               (None, 10, 10, 192)   147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)               (None, 10, 10, 192)   258048      activation_66[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNor (None, 10, 10, 192)   576         conv2d_62[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNor (None, 10, 10, 192)   576         conv2d_67[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_62 (Activation)       (None, 10, 10, 192)   0           batch_normalization_62[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_67 (Activation)       (None, 10, 10, 192)   0           batch_normalization_67[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)               (None, 10, 10, 192)   258048      activation_62[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)               (None, 10, 10, 192)   258048      activation_67[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNor (None, 10, 10, 192)   576         conv2d_63[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNor (None, 10, 10, 192)   576         conv2d_68[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_63 (Activation)       (None, 10, 10, 192)   0           batch_normalization_63[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_68 (Activation)       (None, 10, 10, 192)   0           batch_normalization_68[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePool (None, 10, 10, 768)   0           mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)               (None, 10, 10, 192)   147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)               (None, 10, 10, 192)   258048      activation_63[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)               (None, 10, 10, 192)   258048      activation_68[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)               (None, 10, 10, 192)   147456      average_pooling2d_7[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNor (None, 10, 10, 192)   576         conv2d_61[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNor (None, 10, 10, 192)   576         conv2d_64[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNor (None, 10, 10, 192)   576         conv2d_69[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNor (None, 10, 10, 192)   576         conv2d_70[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_61 (Activation)       (None, 10, 10, 192)   0           batch_normalization_61[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_64 (Activation)       (None, 10, 10, 192)   0           batch_normalization_64[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_69 (Activation)       (None, 10, 10, 192)   0           batch_normalization_69[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_70 (Activation)       (None, 10, 10, 192)   0           batch_normalization_70[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)             (None, 10, 10, 768)   0           activation_61[0][0]              \n",
      "                                                                   activation_64[0][0]              \n",
      "                                                                   activation_69[0][0]              \n",
      "                                                                   activation_70[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)               (None, 10, 10, 192)   147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNor (None, 10, 10, 192)   576         conv2d_73[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_73 (Activation)       (None, 10, 10, 192)   0           batch_normalization_73[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)               (None, 10, 10, 192)   258048      activation_73[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNor (None, 10, 10, 192)   576         conv2d_74[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_74 (Activation)       (None, 10, 10, 192)   0           batch_normalization_74[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)               (None, 10, 10, 192)   147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)               (None, 10, 10, 192)   258048      activation_74[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNor (None, 10, 10, 192)   576         conv2d_71[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNor (None, 10, 10, 192)   576         conv2d_75[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_71 (Activation)       (None, 10, 10, 192)   0           batch_normalization_71[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_75 (Activation)       (None, 10, 10, 192)   0           batch_normalization_75[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)               (None, 4, 4, 320)     552960      activation_71[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)               (None, 4, 4, 192)     331776      activation_75[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNor (None, 4, 4, 320)     960         conv2d_72[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNor (None, 4, 4, 192)     576         conv2d_76[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_72 (Activation)       (None, 4, 4, 320)     0           batch_normalization_72[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_76 (Activation)       (None, 4, 4, 192)     0           batch_normalization_76[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 4, 4, 768)     0           mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)             (None, 4, 4, 1280)    0           activation_72[0][0]              \n",
      "                                                                   activation_76[0][0]              \n",
      "                                                                   max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)               (None, 4, 4, 448)     573440      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNor (None, 4, 4, 448)     1344        conv2d_81[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_81 (Activation)       (None, 4, 4, 448)     0           batch_normalization_81[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)               (None, 4, 4, 384)     491520      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)               (None, 4, 4, 384)     1548288     activation_81[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNor (None, 4, 4, 384)     1152        conv2d_78[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNor (None, 4, 4, 384)     1152        conv2d_82[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_78 (Activation)       (None, 4, 4, 384)     0           batch_normalization_78[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_82 (Activation)       (None, 4, 4, 384)     0           batch_normalization_82[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)               (None, 4, 4, 384)     442368      activation_78[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)               (None, 4, 4, 384)     442368      activation_78[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)               (None, 4, 4, 384)     442368      activation_82[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)               (None, 4, 4, 384)     442368      activation_82[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePool (None, 4, 4, 1280)    0           mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)               (None, 4, 4, 320)     409600      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNor (None, 4, 4, 384)     1152        conv2d_79[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNor (None, 4, 4, 384)     1152        conv2d_80[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNor (None, 4, 4, 384)     1152        conv2d_83[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNor (None, 4, 4, 384)     1152        conv2d_84[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)               (None, 4, 4, 192)     245760      average_pooling2d_8[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNor (None, 4, 4, 320)     960         conv2d_77[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_79 (Activation)       (None, 4, 4, 384)     0           batch_normalization_79[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_80 (Activation)       (None, 4, 4, 384)     0           batch_normalization_80[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_83 (Activation)       (None, 4, 4, 384)     0           batch_normalization_83[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_84 (Activation)       (None, 4, 4, 384)     0           batch_normalization_84[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNor (None, 4, 4, 192)     576         conv2d_85[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_77 (Activation)       (None, 4, 4, 320)     0           batch_normalization_77[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)           (None, 4, 4, 768)     0           activation_79[0][0]              \n",
      "                                                                   activation_80[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 4, 4, 768)     0           activation_83[0][0]              \n",
      "                                                                   activation_84[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_85 (Activation)       (None, 4, 4, 192)     0           batch_normalization_85[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)             (None, 4, 4, 2048)    0           activation_77[0][0]              \n",
      "                                                                   mixed9_0[0][0]                   \n",
      "                                                                   concatenate_1[0][0]              \n",
      "                                                                   activation_85[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)               (None, 4, 4, 448)     917504      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNor (None, 4, 4, 448)     1344        conv2d_90[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_90 (Activation)       (None, 4, 4, 448)     0           batch_normalization_90[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)               (None, 4, 4, 384)     786432      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)               (None, 4, 4, 384)     1548288     activation_90[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNor (None, 4, 4, 384)     1152        conv2d_87[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNor (None, 4, 4, 384)     1152        conv2d_91[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_87 (Activation)       (None, 4, 4, 384)     0           batch_normalization_87[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_91 (Activation)       (None, 4, 4, 384)     0           batch_normalization_91[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)               (None, 4, 4, 384)     442368      activation_87[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)               (None, 4, 4, 384)     442368      activation_87[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)               (None, 4, 4, 384)     442368      activation_91[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)               (None, 4, 4, 384)     442368      activation_91[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePool (None, 4, 4, 2048)    0           mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)               (None, 4, 4, 320)     655360      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNor (None, 4, 4, 384)     1152        conv2d_88[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNor (None, 4, 4, 384)     1152        conv2d_89[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNor (None, 4, 4, 384)     1152        conv2d_92[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNor (None, 4, 4, 384)     1152        conv2d_93[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)               (None, 4, 4, 192)     393216      average_pooling2d_9[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNor (None, 4, 4, 320)     960         conv2d_86[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_88 (Activation)       (None, 4, 4, 384)     0           batch_normalization_88[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_89 (Activation)       (None, 4, 4, 384)     0           batch_normalization_89[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_92 (Activation)       (None, 4, 4, 384)     0           batch_normalization_92[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_93 (Activation)       (None, 4, 4, 384)     0           batch_normalization_93[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNor (None, 4, 4, 192)     576         conv2d_94[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_86 (Activation)       (None, 4, 4, 320)     0           batch_normalization_86[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)           (None, 4, 4, 768)     0           activation_88[0][0]              \n",
      "                                                                   activation_89[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 4, 4, 768)     0           activation_92[0][0]              \n",
      "                                                                   activation_93[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_94 (Activation)       (None, 4, 4, 192)     0           batch_normalization_94[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)            (None, 4, 4, 2048)    0           activation_86[0][0]              \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   concatenate_2[0][0]              \n",
      "                                                                   activation_94[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)        (None, 8)             16781832    mixed10[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 38,584,616\n",
      "Trainable params: 28,781,960\n",
      "Non-trainable params: 9,802,656\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              # optimizer='rmsprop',\n",
    "              optimizer=optimizers.Adam(lr=0.0001),\n",
    "#              optimizer=optimizers.SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=60,\n",
    "#    zca_whitening=True,\n",
    "#    samplewise_center=True,\n",
    "#    featurewise_center=True,\n",
    "    width_shift_range=0.1,\n",
    "#    height_shift_range=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 935 images belonging to 8 classes.\n",
      "Found 160 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=BATCH_SIZE,\n",
    "#    color_mode=\"grayscale\",\n",
    "    shuffle=True,\n",
    "    classes=category_names,\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=20,\n",
    "    classes=category_names,\n",
    "#    color_mode=\"grayscale\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 7s - loss: 2.7391 - acc: 0.2156     \n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 4s - loss: 1.9342 - acc: 0.2883     \n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 4s - loss: 1.8230 - acc: 0.3365     \n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 4s - loss: 1.7321 - acc: 0.3547     \n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 4s - loss: 1.6505 - acc: 0.3979     \n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 5s - loss: 1.6078 - acc: 0.4358     \n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 5s - loss: 1.5288 - acc: 0.4391     \n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 4s - loss: 1.4071 - acc: 0.5117     \n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 4s - loss: 1.4531 - acc: 0.4670     \n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 5s - loss: 1.3242 - acc: 0.5328     \n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 4s - loss: 1.2905 - acc: 0.5532     \n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 4s - loss: 1.2377 - acc: 0.5740     \n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 5s - loss: 1.1317 - acc: 0.6016     \n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 4s - loss: 1.0787 - acc: 0.6000     \n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 4s - loss: 1.1308 - acc: 0.5792     \n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 4s - loss: 1.1288 - acc: 0.6156     \n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 4s - loss: 1.0157 - acc: 0.6498     \n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 4s - loss: 0.9837 - acc: 0.6792     \n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 5s - loss: 0.9903 - acc: 0.6391     \n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 5s - loss: 1.0132 - acc: 0.6378     \n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 4s - loss: 0.9336 - acc: 0.6611     \n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 4s - loss: 0.8255 - acc: 0.7094     \n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 4s - loss: 0.7667 - acc: 0.7334     \n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 4s - loss: 0.8380 - acc: 0.7057     \n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 5s - loss: 0.6780 - acc: 0.7688     \n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 4s - loss: 0.7748 - acc: 0.7461     \n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 4s - loss: 0.7586 - acc: 0.7391     \n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 5s - loss: 0.7088 - acc: 0.7547     \n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 5s - loss: 0.6814 - acc: 0.7653     \n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 4s - loss: 0.6330 - acc: 0.7960     \n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 4s - loss: 0.6153 - acc: 0.7953     \n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 4s - loss: 0.6674 - acc: 0.7892     \n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 4s - loss: 0.6061 - acc: 0.8117     \n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 4s - loss: 0.5822 - acc: 0.7937     \n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 4s - loss: 0.5341 - acc: 0.8072     \n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 4s - loss: 0.5855 - acc: 0.7926     \n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 5s - loss: 0.5336 - acc: 0.8234     \n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 4s - loss: 0.5491 - acc: 0.8087     \n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 4s - loss: 0.5208 - acc: 0.8078     \n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 5s - loss: 0.4875 - acc: 0.8359     \n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 4s - loss: 0.4942 - acc: 0.8307     \n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 4s - loss: 0.4545 - acc: 0.8341     \n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 4s - loss: 0.4407 - acc: 0.8609     \n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 4s - loss: 0.4310 - acc: 0.8597     \n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 4s - loss: 0.4721 - acc: 0.8314     \n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 4s - loss: 0.3746 - acc: 0.8734     \n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 4s - loss: 0.3873 - acc: 0.8740     \n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 5s - loss: 0.3804 - acc: 0.8693     \n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 5s - loss: 0.3724 - acc: 0.8656     \n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 5s - loss: 0.4233 - acc: 0.8756     \n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 4s - loss: 0.3880 - acc: 0.8693     \n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 4s - loss: 0.3664 - acc: 0.8812     \n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 4s - loss: 0.4078 - acc: 0.8536     \n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 4s - loss: 0.3111 - acc: 0.8866     \n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 5s - loss: 0.2824 - acc: 0.9031     \n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 4s - loss: 0.3384 - acc: 0.9025     \n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 4s - loss: 0.2952 - acc: 0.8944     \n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 5s - loss: 0.2798 - acc: 0.9062     \n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 4s - loss: 0.3073 - acc: 0.9007     \n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 4s - loss: 0.2706 - acc: 0.9000     \n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 5s - loss: 0.3091 - acc: 0.8922     \n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 4s - loss: 0.2774 - acc: 0.9038     \n",
      "Epoch 63/200\n",
      "10/10 [==============================] - 4s - loss: 0.2579 - acc: 0.9045     \n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 4s - loss: 0.2037 - acc: 0.9344     \n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 4s - loss: 0.2657 - acc: 0.9198     \n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 4s - loss: 0.3460 - acc: 0.8913     \n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 5s - loss: 0.2354 - acc: 0.9266     \n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 4s - loss: 0.2098 - acc: 0.9451     \n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 4s - loss: 0.2105 - acc: 0.9213     \n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 5s - loss: 0.2407 - acc: 0.9109     \n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 5s - loss: 0.2454 - acc: 0.9157     \n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 5s - loss: 0.3003 - acc: 0.9070     \n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 4s - loss: 0.2021 - acc: 0.9297     \n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 5s - loss: 0.2932 - acc: 0.9094     \n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 4s - loss: 0.2243 - acc: 0.9264     \n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 5s - loss: 0.1994 - acc: 0.9422     \n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 4s - loss: 0.1861 - acc: 0.9379     \n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 5s - loss: 0.1983 - acc: 0.9361     \n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 5s - loss: 0.1702 - acc: 0.9391     \n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 4s - loss: 0.2280 - acc: 0.9276     \n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 4s - loss: 0.2093 - acc: 0.9242     \n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 5s - loss: 0.1617 - acc: 0.9375     \n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 4s - loss: 0.1801 - acc: 0.9426     \n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 4s - loss: 0.1638 - acc: 0.9496     \n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 5s - loss: 0.1868 - acc: 0.9344     \n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 4s - loss: 0.1945 - acc: 0.9317     \n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 4s - loss: 0.1451 - acc: 0.9536     \n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 5s - loss: 0.1620 - acc: 0.9437     \n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 4s - loss: 0.1910 - acc: 0.9417     \n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 5s - loss: 0.1804 - acc: 0.9430     \n",
      "Epoch 91/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s - loss: 0.1763 - acc: 0.9375     \n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 4s - loss: 0.2406 - acc: 0.9183     \n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 4s - loss: 0.1701 - acc: 0.9433     \n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 5s - loss: 0.1843 - acc: 0.9422     \n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 4s - loss: 0.1284 - acc: 0.9567     \n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 4s - loss: 0.1235 - acc: 0.9565     \n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 4s - loss: 0.1348 - acc: 0.9578     \n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 5s - loss: 0.1073 - acc: 0.9630     \n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 5s - loss: 0.1518 - acc: 0.9458     \n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 4s - loss: 0.1321 - acc: 0.9594     \n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 4s - loss: 0.1710 - acc: 0.9392     \n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 4s - loss: 0.1564 - acc: 0.9505     \n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 5s - loss: 0.1343 - acc: 0.9547     \n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 5s - loss: 0.1643 - acc: 0.9487     \n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 4s - loss: 0.1644 - acc: 0.9530     \n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 4s - loss: 0.1486 - acc: 0.9578     \n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 4s - loss: 0.1328 - acc: 0.9574     \n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 4s - loss: 0.1195 - acc: 0.9599     \n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 5s - loss: 0.1316 - acc: 0.9578     \n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 4s - loss: 0.1349 - acc: 0.9520     \n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 4s - loss: 0.1496 - acc: 0.9489     \n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 4s - loss: 0.1267 - acc: 0.9594     \n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 5s - loss: 0.0932 - acc: 0.9671     \n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 4s - loss: 0.1084 - acc: 0.9527     \n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 4s - loss: 0.1065 - acc: 0.9625     \n",
      "Epoch 116/200\n",
      "10/10 [==============================] - 5s - loss: 0.1454 - acc: 0.9558     \n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 4s - loss: 0.1175 - acc: 0.9583     \n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 4s - loss: 0.1089 - acc: 0.9625     \n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 4s - loss: 0.1667 - acc: 0.9439     \n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 4s - loss: 0.1620 - acc: 0.9464     \n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 4s - loss: 0.1072 - acc: 0.9578     \n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 5s - loss: 0.1286 - acc: 0.9596     \n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 4s - loss: 0.1004 - acc: 0.9702     \n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 5s - loss: 0.0752 - acc: 0.9750     \n",
      "Epoch 125/200\n",
      "10/10 [==============================] - 4s - loss: 0.0948 - acc: 0.9630     \n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 4s - loss: 0.0994 - acc: 0.9643     \n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 5s - loss: 0.1118 - acc: 0.9703     \n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 4s - loss: 0.1191 - acc: 0.9605     \n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 4s - loss: 0.0775 - acc: 0.9715     \n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 4s - loss: 0.0966 - acc: 0.9688     \n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 4s - loss: 0.1191 - acc: 0.9621     \n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 4s - loss: 0.1127 - acc: 0.9612     \n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 4s - loss: 0.0844 - acc: 0.9750     \n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 5s - loss: 0.1448 - acc: 0.9549     \n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 4s - loss: 0.1326 - acc: 0.9561     \n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 4s - loss: 0.1759 - acc: 0.9469     \n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 5s - loss: 0.1224 - acc: 0.9581     \n",
      "Epoch 138/200\n",
      "10/10 [==============================] - 4s - loss: 0.0910 - acc: 0.9652     \n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 5s - loss: 0.1253 - acc: 0.9578     \n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 4s - loss: 0.0857 - acc: 0.9731     \n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 4s - loss: 0.1241 - acc: 0.9596     \n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 4s - loss: 0.0823 - acc: 0.9672     \n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 4s - loss: 0.1053 - acc: 0.9552     \n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 4s - loss: 0.1101 - acc: 0.9652     \n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 4s - loss: 0.0948 - acc: 0.9672     \n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 4s - loss: 0.1073 - acc: 0.9652     \n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 4s - loss: 0.0917 - acc: 0.9709     \n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 4s - loss: 0.1081 - acc: 0.9672     \n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 4s - loss: 0.0586 - acc: 0.9803     \n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 4s - loss: 0.1260 - acc: 0.9675     \n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 5s - loss: 0.0792 - acc: 0.9688     \n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 4s - loss: 0.1094 - acc: 0.9615     \n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 4s - loss: 0.1187 - acc: 0.9637     \n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 4s - loss: 0.1110 - acc: 0.9594     \n",
      "Epoch 155/200\n",
      "10/10 [==============================] - 4s - loss: 0.0979 - acc: 0.9749     \n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 4s - loss: 0.0907 - acc: 0.9686     \n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 4s - loss: 0.0600 - acc: 0.9750     \n",
      "Epoch 158/200\n",
      "10/10 [==============================] - 4s - loss: 0.0915 - acc: 0.9643     \n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 4s - loss: 0.0737 - acc: 0.9796     \n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 5s - loss: 0.0836 - acc: 0.9781     \n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 4s - loss: 0.0973 - acc: 0.9668     \n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 4s - loss: 0.1247 - acc: 0.9506     \n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 4s - loss: 0.1107 - acc: 0.9719     \n",
      "Epoch 164/200\n",
      "10/10 [==============================] - 4s - loss: 0.0811 - acc: 0.9659     \n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 4s - loss: 0.0871 - acc: 0.9771     \n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 4s - loss: 0.1011 - acc: 0.9672     \n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 4s - loss: 0.1277 - acc: 0.9590     \n",
      "Epoch 168/200\n",
      "10/10 [==============================] - 4s - loss: 0.0830 - acc: 0.9668     \n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 5s - loss: 0.0733 - acc: 0.9750     \n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 4s - loss: 0.0656 - acc: 0.9749     \n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 4s - loss: 0.0425 - acc: 0.9859     \n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 5s - loss: 0.0514 - acc: 0.9797     \n",
      "Epoch 173/200\n",
      "10/10 [==============================] - 5s - loss: 0.0910 - acc: 0.9671     \n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 4s - loss: 0.0654 - acc: 0.9756     \n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 4s - loss: 0.0744 - acc: 0.9719     \n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 4s - loss: 0.1136 - acc: 0.9693     \n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 4s - loss: 0.0638 - acc: 0.9740     \n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 5s - loss: 0.0730 - acc: 0.9766     \n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 4s - loss: 0.1169 - acc: 0.9605     \n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s - loss: 0.0625 - acc: 0.9834     \n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 5s - loss: 0.0633 - acc: 0.9797     \n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 4s - loss: 0.0847 - acc: 0.9756     \n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 4s - loss: 0.0618 - acc: 0.9747     \n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 4s - loss: 0.0873 - acc: 0.9719     \n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 4s - loss: 0.0562 - acc: 0.9812     \n",
      "Epoch 186/200\n",
      "10/10 [==============================] - 4s - loss: 0.0765 - acc: 0.9843     \n",
      "Epoch 187/200\n",
      "10/10 [==============================] - 4s - loss: 0.1132 - acc: 0.9656     \n",
      "Epoch 188/200\n",
      "10/10 [==============================] - 4s - loss: 0.0677 - acc: 0.9718     \n",
      "Epoch 189/200\n",
      "10/10 [==============================] - 4s - loss: 0.1221 - acc: 0.9615     \n",
      "Epoch 190/200\n",
      "10/10 [==============================] - 4s - loss: 0.0584 - acc: 0.9812     \n",
      "Epoch 191/200\n",
      "10/10 [==============================] - 4s - loss: 0.0599 - acc: 0.9787     \n",
      "Epoch 192/200\n",
      "10/10 [==============================] - 4s - loss: 0.0767 - acc: 0.9740     \n",
      "Epoch 193/200\n",
      "10/10 [==============================] - 5s - loss: 0.0987 - acc: 0.9672     \n",
      "Epoch 194/200\n",
      "10/10 [==============================] - 4s - loss: 0.0610 - acc: 0.9787     \n",
      "Epoch 195/200\n",
      "10/10 [==============================] - 4s - loss: 0.0595 - acc: 0.9787     \n",
      "Epoch 196/200\n",
      "10/10 [==============================] - 4s - loss: 0.0664 - acc: 0.9781     \n",
      "Epoch 197/200\n",
      "10/10 [==============================] - 4s - loss: 0.0460 - acc: 0.9865     \n",
      "Epoch 198/200\n",
      "10/10 [==============================] - 4s - loss: 0.1004 - acc: 0.9643     \n",
      "Epoch 199/200\n",
      "10/10 [==============================] - 4s - loss: 0.0729 - acc: 0.9828     \n",
      "Epoch 200/200\n",
      "10/10 [==============================] - 4s - loss: 0.0905 - acc: 0.9621     \n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS,\n",
    "#    validation_data=validation_generator,\n",
    "#    validation_steps=1\n",
    "#    nb_val_samples=nb_validation_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147351"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string = model.to_json()\n",
    "open(os.path.join('inception_model.json'), 'w').write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(os.path.join('inception_model_weights.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 学習を可視化\n",
    "with open(\"history.pickle\", mode='wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEICAYAAACuxNj9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQRAElfwDCwuaEG/b3PQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa700b5978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5be7af23852e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAACGCAYAAADQHI0rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa4778d0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('history.pickle', mode='rb') as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history['loss'], \"-\", label=\"loss\",)\n",
    "plt.title('training')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='center right')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(history['acc'], \"-\", label=\"acc\",)\n",
    "plt.ylabel('acc')\n",
    "plt.legend(loc='center right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history['val_loss'], \"-\", label=\"val_loss\")\n",
    "plt.title('validation')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('val_loss')\n",
    "plt.legend(loc='center right')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(history['val_acc'], \"-\", label=\"val_acc\")\n",
    "plt.ylabel('val_acc')\n",
    "plt.legend(loc='center right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
